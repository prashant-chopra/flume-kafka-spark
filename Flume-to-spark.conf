# Name the components on this agent
sparkpc.sources = logsource
sparkpc.sinks = sparksink hdfssink
sparkpc.channels = sparkchannel hdfschannel

# Describe/configure the source
sparkpc.sources.logsource.type = exec
sparkpc.sources.logsource.command = tail -F /opt/gen_logs/logs/access.log

# Describe the logger sink
sparkpc.sinks.sparksink.type = org.apache.spark.streaming.flume.sink.SparkSink
sparkpc.sinks.sparksink.hostname = gw01.itversity.com
sparkpc.sinks.sparksink.port = 19999
sparkpc.sinks.sparksink.channel = memoryChannel

#Desceribe the hdfs sink
sparkpc.sinks.hdfssink.type = hdfs
sparkpc.sinks.hdfssink.hdfs.path = hdfs://nn01.itversity.com:8020/user/prashantchopra/wlabssa/sparkpc
sparkpc.sinks.hdfssink.hdfs.fileType = DataStream
sparkpc.sinks.hdfssink.hdfs.rollInterval = 120
sparkpc.sinks.hdfssink.hdfs.rollSize = 10485760
sparkpc.sinks.hdfssink.hdfs.rollCount = 30
sparkpc.sinks.hdfssink.hdfs.filePrefix = retail
sparkpc.sinks.hdfssink.hdfs.fileSuffix = .txt
sparkpc.sinks.hdfssink.hdfs.inUseSuffix = .tmp
sparkpc.sinks.hdfssink.hdfs.useLocalTimeStamp = true

# Use a channel which buffers events in memory
sparkpc.channels.sparkchannel.type = memory
sparkpc.channels.sparkchannel.capacity = 1000
sparkpc.channels.sparkchannel.transactionCapacity = 100

sparkpc.channels.hdfschannel.type = file
sparkpc.channels.hdfschannel.capacity = 1000
sparkpc.channels.hdfschannel.transactionCapacity = 100
sparkpc.channels.hdfschannel.checkpointInterval = 300

# Bind the source and sink to the channel
sparkpc.sources.logsource.channels = hdfschannel sparkchannel
sparkpc.sinks.sparksink.channel = sparkchannel
sparkpc.sinks.hdfssink.channel = hdfschannel
