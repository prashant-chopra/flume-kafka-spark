# flume-to-logger-hdfs.conf: Read data from logs and write it to both logger and hdfs
# flume command to start the agent - flume-ng agent --name fmp --conf /home/prashantchopra/flume/conf --conf-file flume-to-logger-hdfs.conf

# Name the components on this agent
fmp.sources = logsource
fmp.sinks = loggersink hdfssink
fmp.channels = loggerchannel hdfschannel

# Describe/configure the source
fmp.sources.logsource.type = exec
fmp.sources.logsource.command = tail -F /opt/gen_logs/logs/access.log

# Describe the logger sink
fmp.sinks.loggersink.type = logger

#Desceribe the hdfs sink
fmp.sinks.hdfssink.type = hdfs
fmp.sinks.hdfssink.hdfs.path = hdfs://nn01.mycluster.com:8020/user/prashantchopra/labs/flumepc
fmp.sinks.hdfssink.hdfs.fileType = DataStream
fmp.sinks.hdfssink.hdfs.rollInterval = 120
fmp.sinks.hdfssink.hdfs.rollSize = 10485760
fmp.sinks.hdfssink.hdfs.rollCount = 30
fmp.sinks.hdfssink.hdfs.filePrefix = retail
fmp.sinks.hdfssink.hdfs.fileSuffix = .txt
fmp.sinks.hdfssink.hdfs.inUseSuffix = .tmp
fmp.sinks.hdfssink.hdfs.useLocalTimeStamp = true

# Use a channel which buffers events in memory
fmp.channels.loggerchannel.type = memory
fmp.channels.loggerchannel.capacity = 1000
fmp.channels.loggerchannel.transactionCapacity = 100

#Use a channel which buffers events in file for HDFS sink
fmp.channels.hdfschannel.type = file
fmp.channels.hdfschannel.capacity = 1000
fmp.channels.hdfschannel.transactionCapacity = 100
fmp.channels.hdfschannel.checkpointInterval = 300

# Bind the source and sink to the channel
fmp.sources.logsource.channels = hdfschannel loggerchannel
fmp.sinks.loggersink.channel = loggerchannel
fmp.sinks.hdfssink.channel = hdfschannel
